{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1_Y75QXJS6h"
   },
   "source": [
    "## Import TensorFlow and other libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "assert \"SDI/codespace/dataset_training\" in os.getcwd().replace(\"\\\\\", \"/\")\n",
    "if not os.getcwd().endswith(\"dataset_training\"):\n",
    "    os.chdir(\"../..\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T06:14:50.494760Z",
     "iopub.status.busy": "2022-12-14T06:14:50.494469Z",
     "iopub.status.idle": "2022-12-14T06:14:50.718144Z",
     "shell.execute_reply": "2022-12-14T06:14:50.717454Z"
    },
    "id": "KmKRDJWgsFYa"
   },
   "outputs": [],
   "source": [
    "from GAF.preprocessing.features_extractors.raw_extractor import RawExtractor\n",
    "from GAF.preprocessing.data_translator.gaf_translator import GafTranslator\n",
    "from GAF.preprocessing.preprocessor import Preprocessor\n",
    "\n",
    "TIME_PER_SAMPLE = 2\n",
    "WINDOWS = 4\n",
    "RESAMPLE_MS = TIME_PER_SAMPLE * 1000 // WINDOWS\n",
    "SAMPLES_PER_MINUTE = 60\n",
    "PATH = f\"data/processed/fixed_{SAMPLES_PER_MINUTE}\"\n",
    "ANOMALIES_PATH = f\"anomalies/processed/fixed_{SAMPLES_PER_MINUTE}\"\n",
    "AXIS_WINDOWS_AMOUNT = (\n",
    "    TIME_PER_SAMPLE * SAMPLES_PER_MINUTE\n",
    ")  # 4 windows * 0.500 s/window * 60 points-in-sample/s = 120 points-in-sample\n",
    "AXES = [\"x\", \"y\", \"z\", \"tot\"]\n",
    "\n",
    "extractor = RawExtractor(resample_amount=RESAMPLE_MS)\n",
    "preprocess = Preprocessor(extractor, packed_windows=WINDOWS, path=PATH)\n",
    "anomalies_preprocess = Preprocessor(extractor, packed_windows=WINDOWS, path=ANOMALIES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-14T06:14:50.721788Z",
     "iopub.status.busy": "2022-12-14T06:14:50.721160Z",
     "iopub.status.idle": "2022-12-14T06:14:50.728196Z",
     "shell.execute_reply": "2022-12-14T06:14:50.727587Z"
    },
    "id": "UmuCPVYKsKKx"
   },
   "outputs": [],
   "source": [
    "sensor = \"gyroscope\"\n",
    "\n",
    "\n",
    "class SmallGafDatasetLoader:\n",
    "    def __init__(self, preprocess, sensor):\n",
    "        self.data, self.labels, self.ids = preprocess.load_dataset_sensor(sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SmallGafDatasetLoader(preprocess, sensor)\n",
    "anomaly_dataset = SmallGafDatasetLoader(anomalies_preprocess, sensor)\n",
    "\n",
    "# To get the name used by the program we will use this\n",
    "preprocess_real = Preprocessor(\n",
    "    extractor,\n",
    "    translators=[GafTranslator(AXIS_WINDOWS_AMOUNT, WINDOWS)],\n",
    "    packed_windows=WINDOWS,\n",
    "    path=PATH,\n",
    ")\n",
    "anomalies_preprocess_real = Preprocessor(\n",
    "    extractor,\n",
    "    translators=[GafTranslator(AXIS_WINDOWS_AMOUNT, WINDOWS)],\n",
    "    packed_windows=WINDOWS,\n",
    "    path=ANOMALIES_PATH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(train_dataset.ids).shape)\n",
    "print(np.array(train_dataset.data).shape)\n",
    "print(np.array(anomaly_dataset.ids).shape)\n",
    "print(np.array(anomaly_dataset.data).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = GafTranslator(AXIS_WINDOWS_AMOUNT, WINDOWS, method=\"summation\")\n",
    "\n",
    "\n",
    "# translator = GafTranslator(AXIS_WINDOWS_AMOUNT, WINDOWS, method='difference')\n",
    "def save_info(dataset, output_dir_name):\n",
    "    print(np.array(dataset.ids).shape)\n",
    "    print(np.array(dataset.data).shape)\n",
    "    for axis in AXES:\n",
    "        i = 0\n",
    "        for gaf_image in translator.translate_axis_yield(dataset.data, axis):\n",
    "            path = pathlib.Path(f\"{output_dir_name}/{axis}/{i}.npy\")\n",
    "            path.parent.mkdir(parents=True, exist_ok=True)\n",
    "            # print(path, end=\"\\r\")\n",
    "            f = gzip.GzipFile(path, \"w\")\n",
    "            np.save(f, gaf_image)\n",
    "            i += 1\n",
    "\n",
    "            # loading example\n",
    "            # f = gzip.GzipFile(path, \"r\")\n",
    "            # m = np.load(f)\n",
    "            # print(m.shape)\n",
    "\n",
    "\n",
    "save_info(train_dataset, preprocess_real.get_file_name(sensor, [translator]))\n",
    "save_info(anomaly_dataset, anomalies_preprocess_real.get_file_name(sensor, [translator]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "autoencoder.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "3b7e9cb8e453d6cda0fe8c8dd13f891a1f09162f0e7c66ffeae7751a7aecf00d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
